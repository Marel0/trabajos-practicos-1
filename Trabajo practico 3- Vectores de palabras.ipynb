{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"imagenes/cabecera.png\" width=\"900\" align=\"center\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico 3: Vectores de palabras\n",
    "\n",
    "## Curso Procesamiento de Lenguaje Natural \n",
    "\n",
    "### Maestría en Tecnologías de la información\n",
    "\n",
    "\n",
    "\n",
    "**Trabajo práctico porpuesto por:** Julio Waissman Vilanova (julio.waissman@unison.mx)\n",
    "\n",
    "**Desarrollado por:** _Poner tu nombre y correo electrónico aquí_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este trabajo práctico vamos a generar y usar un modelo de vectores de inserciones de palabras. Para este proyecto práctico, contamos con un corpus de preguntas que se han hecho en *Stackoverflow* para diferentes lenguajes de programación.\n",
    "\n",
    "La idea final es contar con una función que, ante una frase, determine si es una pregunta sobre algun lenguaje de programación, que determine el lenguaje de programación, y que los de una recomendación sobre una pregunta similar. Dado que el corpus lo tengo solo en inglés (casi no hay preguntas técnicas en español), vamos a hacer todo en inglés para este ejercicio. Para la detectar si una frase es de interés nuestro, se utiliza un corpus de diálogos de peliculas de cine.\n",
    "\n",
    "Si bien vamos a hacer todos los pasos juntos, este corpus ya es a escala real, y muchos de los problemas que se pueden tener en el desarrollo del trabajo práctico pueden ser de orden de memoria o de tiempo de procesamiento. Espero que se encuentren con algunos de esos problemas (aunque procuraré ahorrarselos) con el fin que obtengan una experiencia sobre el tipo de problemáticas que se tienen al desarrollar y usar modelos de vectores de palabras.\n",
    "\n",
    "\n",
    "## 1. Obteniendo los documentos\n",
    "\n",
    "Los documentos se encuentran en dos archivos *pickle*, los cuales los precargamos con los módulos necesarios para el trabajo práctico.\n",
    "\n",
    "La llamada a todas las librerías que vas a necesitar, así como cargar los datos con los que vas a desarrollar la libreta, los dejo listos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171570</th>\n",
       "      <td>45887455</td>\n",
       "      <td>What is the difference between node.js and ayo...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171571</th>\n",
       "      <td>45887857</td>\n",
       "      <td>Why do sequential containers have both size_ty...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171572</th>\n",
       "      <td>45892983</td>\n",
       "      <td>why 1 + + \"1\" === 2; +\"1\" + + \"1\" === 2 and \"1...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171573</th>\n",
       "      <td>45893693</td>\n",
       "      <td>Why does the first line work but the second li...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171574</th>\n",
       "      <td>45898184</td>\n",
       "      <td>Can I safely convert struct of floats into flo...</td>\n",
       "      <td>c_cpp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          post_id                                              title  \\\n",
       "2171570  45887455  What is the difference between node.js and ayo...   \n",
       "2171571  45887857  Why do sequential containers have both size_ty...   \n",
       "2171572  45892983  why 1 + + \"1\" === 2; +\"1\" + + \"1\" === 2 and \"1...   \n",
       "2171573  45893693  Why does the first line work but the second li...   \n",
       "2171574  45898184  Can I safely convert struct of floats into flo...   \n",
       "\n",
       "                tag  \n",
       "2171570  javascript  \n",
       "2171571       c_cpp  \n",
       "2171572  javascript  \n",
       "2171573  javascript  \n",
       "2171574       c_cpp  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218604</th>\n",
       "      <td>Lord Chelmsford seems to want me to stay back ...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218605</th>\n",
       "      <td>I'm to take the Sikali with the main column to...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218606</th>\n",
       "      <td>Your orders, Mr Vereker?</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218607</th>\n",
       "      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218608</th>\n",
       "      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       tag\n",
       "218604  Lord Chelmsford seems to want me to stay back ...  dialogue\n",
       "218605  I'm to take the Sikali with the main column to...  dialogue\n",
       "218606                           Your orders, Mr Vereker?  dialogue\n",
       "218607  Good ones, yes, Mr Vereker. Gentlemen who can ...  dialogue\n",
       "218608  Colonel Durnford... William Vereker. I hear yo...  dialogue"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las etiquetas (lenguajes) existentes son:\n",
      "       Etiqueta  Entradas\n",
      "             c#    394451\n",
      "           java    383456\n",
      "     javascript    375867\n",
      "            php    321752\n",
      "          c_cpp    281300\n",
      "         python    208607\n",
      "           ruby     99930\n",
      "              r     36359\n",
      "             vb     35044\n",
      "          swift     34809\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "!bunzip2 datos/preguntas_so.pkl.bz2\n",
    "df_post = pd.read_pickle('datos/preguntas_so.pkl')\n",
    "df_dialog = pd.read_pickle('datos/dialogos.pkl')\n",
    "!bzip2 datos/preguntas_so.pkl\n",
    "\n",
    "display(df_post.tail())\n",
    "display(df_dialog.tail())\n",
    "\n",
    "tags = Counter(df_post.loc[:,'tag'])\n",
    "print(\"Las etiquetas (lenguajes) existentes son:\")\n",
    "print(\"{:>15s}{:>10}\".format('Etiqueta', 'Entradas'))\n",
    "for (tag, numero) in tags.most_common():\n",
    "    print(\"{:>15s}{:10d}\".format(tag, numero))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como podemos observar hay más de dos millones de documentos sobre consultas a *stack overflow* mientras que los diálogos de películas son aproximadamente 200 mil.\n",
    "\n",
    "Lo que vamos a hacer a lo largo del proyecto es lo siguiente:\n",
    "\n",
    "1. Normalizar y guardar cada una de las frases de ambos corpus y guardarlo en un archivo /texto plano/ (en unicode, por supuesto).\n",
    "\n",
    "2. Utilizar FastText para obtener un modelo de palabras\n",
    "\n",
    "3. Realizar una función que permita codificar frases con nuestro modelo\n",
    "\n",
    "4. Desarrollar un clasificador que determine si una frase trata sobre posibles preguntas a /Stackoverflow/, o no.\n",
    "\n",
    "5. Desarrollar un clasificador que determine el tema (lenguaje de programación) de una frase.\n",
    "\n",
    "6. Desarrollar un recomendador que seleccione la pregunta más parecida a una frase.\n",
    "\n",
    "7. Poner todo junto.\n",
    "\n",
    "Por supuesto, para todas las etapas no es seguro que usar modelos de vectores de palabras sea la mejor opción, pero la idea de esta libreta es practicar semántica distribuida y sus aplicaciones.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. Generando un modelo de palabras específico al problema\n",
    "\n",
    "Para esto, lo priero es desarrollar un método de normalización de textos. \n",
    "\n",
    "**Genera un método de normalización de textos tal que:**\n",
    "1. **Convierta a minúsculas todas las palabras.**\n",
    "2. **Cambie los caracteres `[`, `]`, `(`, `)`, `{`, `}`, `|`, `/`, `@`, `;` y `,` por un espacio en blanco.**\n",
    "3. **Elimine todos los caracteres que no sean alfabéticos, digitos, o los caracteres `#`, `+`, `_` o el espacio en blanco.**\n",
    "4. **Elimina las palabras vacias.**\n",
    "\n",
    "**Para esto, compila las expresiones regulares que uses antes, ya que eso ahorrará muchisimo tiempo más adelante. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "\n",
    "\n",
    "# Función de normalización\n",
    "def normaliza_texto(texto):\n",
    "    \"\"\"\n",
    "    Normaliza texto y lo divide en tokens (asumiendo el espacio como separación de tokens)\n",
    "    \n",
    "    :param texto: Una cadena de caracteres con el texto a normalizar\n",
    "    \n",
    "    :return: Una lista de tokens (strings)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ahora vamos a utilizar tu función de normalización para hacer un archivote con todas las frases de ambos `dataframes` ya tratados. Esto hay que hacerlo en forma secuencial, para no tener problemas de memoria. Esta parte la dejo porgramada y lista para usarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe el resultado en un archivo de texto\n",
    "with open('datos/stackovr_normalizados.txt', 'w', encoding='utf8') as fp:\n",
    "    for documento in df_post['title'].values:\n",
    "        fp.write(normaliza_texto(documento) + '\\n')\n",
    "    for documento in df_dialog['text'].values:\n",
    "        fp.write(normaliza_texto(documento) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a desarrollar un modelo. Si quisieramos entrenar el modelo en python, muy seguramente la libreta de jupyter se va a resetear por falta de memoria. Es por esta razón que es necesario utilizar la versión compilada de [*FastText*](https://fasttext.cc). En [esta página de documentación](https://fasttext.cc/docs/en/cheatsheet.html) viene los comandos mínimos para las diferentes tareas que pueden hacerse con *FastText*. Revisalas y verifica que puedes construir un modelo de vector de palabras con una dimensión de 100.\n",
    "\n",
    "Cuando ejecutes el comando tardará bastante tiempo en generar el modelo, pero estará escribiendo información en la salida con el fin que estés seguro que está trabajando.\n",
    "\n",
    "**Genera un modelo de fasttext con los datos de entrada `datos/stackovr_normalizados.txt`. Guarda el modelo en el archivo `modelos/fstxt_model`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![ESCRIBE AQUÍ EL COMANDO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a probar si funciona, cargandolo en la libreta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = gensim.models.FastText.load_fasttext_format('modelos/fstxt_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué pasa con este modelo cuando proguntamos el típico `king - man + woman?`?, Justifica tu respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7870528697967529),\n",
       " ('wealthy', 0.7674549221992493),\n",
       " ('daughterinlaws', 0.7634091973304749),\n",
       " ('womans', 0.7623488903045654),\n",
       " ('catwoman', 0.7604762315750122)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Y que pasaría con `python - dictionary + java`?**\n",
    "\n",
    "**¿Qué otra relación encuentras su resultado particularmente interesante?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hashmap', 0.7939369082450867),\n",
       " ('arraylistnamevaluepair', 0.7892711162567139),\n",
       " ('arraylisthashmap', 0.7810637950897217),\n",
       " ('arraylistcustomobject', 0.7795299291610718),\n",
       " ('arrayliststring', 0.776357889175415)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.most_similar(positive=['dictionary', 'java'], negative=['python'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por útimo revisemas a que etiqueta se parece más una palabra (si es que existe).\n",
    "\n",
    "1. **Verifica que cada `tag` se parezca a el mismo. Es una manera trivial de verificar el modelo.**\n",
    "2. **Verifica cuales son los `tags` que se parecen entre si**\n",
    "3. **Verifica si expresiones muy tipicas de un lenguaje efectivamente reconoce a ese lenguaje como el más cercano (o de las mas cercanos), por ejemplo `malloc`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridad de los 'tags' con la palabra java\n",
      "swift          0.4261448733027299\n",
      "c#             0.6097577096650382\n",
      "r              0.46793525039293277\n",
      "ruby           0.504294792051381\n",
      "java           0.9999999737444454\n",
      "python         0.5606679928235346\n",
      "javascript     0.5849551802099667\n",
      "php            0.5286095699599829\n",
      "vb             0.4789812059497006\n",
      "c_cpp          0.3565544366319904\n"
     ]
    }
   ],
   "source": [
    "tags_vec = np.zeros((len(tags), modelo.vector_size))\n",
    "for (i, tag) in enumerate(tags.keys()):\n",
    "    tags_vec[i,:] = modelo[tag]\n",
    "\n",
    "palabra = 'java'\n",
    "sims = modelo.wv.cosine_similarities(modelo[palabra], tags_vec)\n",
    "\n",
    "print(\"Similaridad de los 'tags' con la palabra \" + palabra)\n",
    "for (tag, sim) in zip(tags.keys(), sims):\n",
    "    print(\"{:15}{}\".format(tag, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectores de frases\n",
    "\n",
    "Ahora si, ya tenemos un modelo entrenado para nuestro problema particular, y confiamos en él. Ahora lo que necesitamos es desarrollar una función que permita parametrizar una frase y no solo una palabra. Como vimos en clase, la mejor manera de parametrizar una frase es encontrando la codificación para cada palabra que exista en el vocabulario, y luego calculando la media de todos los vectores.\n",
    "\n",
    "Dado que estamos utilizando *FastText*, es posible encontrar los vectores de palabras que no existan en el vocabulario, por lo que es mejor probar si las palabras tienen codificación o no.\n",
    "\n",
    "** Desarrolla la función `doc_a_vec`**\n",
    "\n",
    "Ayuda: si aplicamos \n",
    "```python\n",
    "modelo['palabra otra_palabra tercera_palabra]\n",
    "```\n",
    "\n",
    "obtenemos un ndarray de /shape/ `[3, 100]`\n",
    "\n",
    "y recuerda que buscamos a la salida un ndarray de *shape* `[100, ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_a_vec(doc, modelo):\n",
    "    \"\"\"\n",
    "    Convierte un documento en vector utilizando\n",
    "    el viejo truco de sacar la media de las palabras\n",
    "    que existen en el vocabulario.\n",
    "    \n",
    "    :param doc: Una lista con las palabras del documento\n",
    "    :param modelo: Un modelo tipo FastText o cualquiero otro modelo de vectores\n",
    "    \n",
    "    :return un vector que representa un documento\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generando un discriminador de pregunta técnica vs texto normal con el modelo\n",
    "\n",
    "Para realizar el modelado, vamos a seleccionar un número de titulos de preguntas a *Stackoverflow* de la misma dimensión que el número de diálogos de cine, con la idea de entrenar un clasificador con el mísmo numero de ejemplos de cada clase y evitar que esté desbalanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_muestras = df_dialog.shape[0]\n",
    "positivos = df_post['title'].sample(num_muestras, random_state=10).values\n",
    "negativos = df_dialog['text'].values\n",
    "\n",
    "x_texto = np.r_[positivos, negativos]\n",
    "y = np.r_[np.ones(num_muestras), -1 * np.ones(num_muestras)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a comvertir estos datos a vectores de frases con la funcion que realizaste. Fijate en dos cosas en esta función:\n",
    "\n",
    "1. Convertimos todas las entradas a `float32`, ya que numpy se basa en `float64` y es mucha la memoria sin que aporte realmente mucho más.\n",
    "\n",
    "2. Verificamos cuantas frases, o estaban en blanco (i.e. puras palabras de paro) o no pudieron codificarse (i.e. puras palabras OOV que no pudo generalizar *FastText*). Si tenemos suerte, habrá menos del 2% de frases sin clasificar, y la mayoría pertenecen a una sola clase.\n",
    "\n",
    "**Revisa que sea el caso, y si no lo es, regresa tus pasos para ver que tienes que modificar.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin poner positivos: 22,\tnegativos: 2081\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((2 * num_muestras, modelo.vector_size), dtype=np.float32)\n",
    "pos_0, neg_0 = 0, 0\n",
    "for (i, doc) in enumerate(x_texto):\n",
    "    docn = normaliza_texto(doc).split()\n",
    "    try:\n",
    "        x[i, :] = doc_a_vec(docn, modelo)\n",
    "    except:\n",
    "        if y[i] > 0:\n",
    "            pos_0 += 1\n",
    "        else:\n",
    "            neg_0 += 1\n",
    "        \n",
    "print(\"sin poner positivos: {},\\tnegativos: {}\".format(pos_0, neg_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divide los conjuntos de datos `x`y `y`en conjuntos de aprendizaje y validación (10% de datos de validación), y ajusta un clasificador por regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "x_entrena, x_valida, y_entrena, y_valida = # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "clf_tipo = # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "# AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, con una función reporte, vamos a verificar sobre el conjunto de datos de validación si el clasificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporte(y, y_est, labels=None):\n",
    "    print(\"\\nPorcentaje de acierto: {}\".format(accuracy_score(y, y_est)))\n",
    "    print(\"\\nPrecisión, recall y f1-score\")\n",
    "    print(classification_report(y, y_est, target_names=labels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Verifica que los datos de validación tienen un error menor al 2%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Para los datos de validación\n",
      "========================================\n",
      "\n",
      "Porcentaje de acierto: 0.992383696994648\n",
      "\n",
      "Precisión, recall y f1-score\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.99      0.99      0.99     22020\n",
      "        1.0       0.99      0.99      0.99     21702\n",
      "\n",
      "avg / total       0.99      0.99      0.99     43722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valida_est = clf_tipo.predict(x_valida)\n",
    "print(\"\\n\\nPara los datos de validación\\n\" + 40*\"=\")\n",
    "reporte(y_valida, y_valida_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último guardamos el clasificador, por si algo pasa, ya no tenemos que repetir todos estos pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelos/clf_tipo.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(clf_tipo, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generando un clasificador de tópicos con el modelo\n",
    "\n",
    "Para este ejercicio, los pasos son casi iguales que para el inciso anterior, solo que con una dificultad mayor, ya que la cantidad de datos de entrenamiento es bestial y el algoritmo de regresion logística tal cual no va a funcionar (puedes verificarlo).\n",
    "\n",
    "Primero vamos a convertir *todos* los titulos de las preguntas de *Stackoverflow* en vectores. Esto se va a llevar una buena cantidad de minutos (o más dependiendo del número de procesadores y la velocidad de tu equipo). De nuevo, espereríamos que la cantidad de frases sin codificar fueran despreciables respecto al volumen de frases de cada `tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos sin representación densa por etiqueta\n",
      "Para la etiqueta 'php' hay 17 de 321752\n",
      "Para la etiqueta 'javascript' hay 16 de 375867\n",
      "Para la etiqueta 'python' hay 10 de 208607\n",
      "Para la etiqueta 'r' hay 5 de 36359\n",
      "Para la etiqueta 'java' hay 21 de 383456\n",
      "Para la etiqueta 'vb' hay 4 de 35044\n",
      "Para la etiqueta 'c_cpp' hay 46 de 281300\n",
      "Para la etiqueta 'swift' hay 1 de 34809\n",
      "Para la etiqueta 'ruby' hay 4 de 99930\n",
      "Para la etiqueta 'c#' hay 26 de 394451\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((df_post.shape[0], modelo.vector_size), dtype=np.float32)\n",
    "tags_lost = {tag: 0 for tag in tags.keys()}\n",
    "\n",
    "for (i, doc) in enumerate(df_post['title'].values):\n",
    "    docn = normaliza_texto(doc).split()\n",
    "    try:\n",
    "        x[i, :] = doc_a_vec(docn, modelo)\n",
    "    except:\n",
    "        tags_lost[df_post.loc[i, 'tag']] += 1\n",
    "print(\"Documentos sin representación densa por etiqueta\")\n",
    "for tag in tags.keys():\n",
    "    print(\"Para la etiqueta '{}' hay {} de {}\".format(tag, tags_lost[tag], tags[tag]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y guardamos los datos tratados (comprimiendolos al mismo tiempo) para no tener que volverlos a generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('datos/vector_x', x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrena un clasificador de tema (lenguaje de programación) con los daots que tenemos, utilizando el 20% de validación.**\n",
    "\n",
    "Ayuda: Checa la función SGDClassifier (Gradiente estocástico) para grandes volumenes de datos y revisa en que caso es equivalente a una regresión logística y cuando una máquina de vector de soporte. Usa la que consideres mñas conveniente, pero deja explicitamente cual usaste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_entrena, x_valida, y_entrena, y_valida = # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "clf_tema = # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "\n",
    "# AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revisa que el error en los datos de validación no exceda el 25%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Para los datos de validación\n",
      "========================================\n",
      "\n",
      "Porcentaje de acierto: 0.7859525920127096\n",
      "\n",
      "Precisión, recall y f1-score\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         c#       0.75      0.78      0.77     78965\n",
      "      c_cpp       0.77      0.79      0.78     56373\n",
      "       java       0.82      0.81      0.82     76788\n",
      " javascript       0.76      0.83      0.80     74808\n",
      "        php       0.81      0.79      0.80     64546\n",
      "     python       0.86      0.83      0.84     41799\n",
      "          r       0.88      0.76      0.82      7160\n",
      "       ruby       0.87      0.81      0.84     19967\n",
      "      swift       0.85      0.38      0.53      6905\n",
      "         vb       0.02      0.01      0.01      7004\n",
      "\n",
      "avg / total       0.78      0.79      0.78    434315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_valida_est = clf_tema.predict(x_valida)\n",
    "print(\"\\n\\nPara los datos de validación\\n\" + 40*\"=\")\n",
    "reporte(y_valida, y_valida_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"modelos/clf_tema.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(clf_tema, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construyendo un recomendador a partir del modelo\n",
    "\n",
    "Ahora, si podemos detectar si la frase parece una pregunta de *Stackoverflow*, y sobre que tema es la pregunta, deberíamos ser capaces de recomendar checar alguna de las preguntas existentes (o varias en orden de importancia, pero por el momento nos quedamos en una).\n",
    "\n",
    "Par eso, pues simplemente vamos a comparar la frase (en forma de vector), con las frases existentes utilizando la *similaridad coseno*. Primero vamos a obtener los indices de llas frases de cada una de las etiquetas, y vamos a guardar ese vector de indices en un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_post.loc[:,'tag']\n",
    "indices = {tag: np.where( y == tag)[0]\n",
    "           for tag in tags.keys()\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que hacer el recomendador.\n",
    "\n",
    "**Desarrolla la función que encuentre el indice del vector de x mas similar a pregunta_vec**\n",
    "\n",
    "Ayuda: revisa modelo.wv.cosine_similarities. Ten cuidado, si algun vector es de puros 0, entonces te puedes encontrar un NaN entre las similaridades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomienda_pregunta(modelo, pregunta_vec, x):\n",
    "    \"\"\"\n",
    "    Encuentra el índice del vector de x con mayor simiaridad a pregunta_vec\n",
    "    utilizando la similaridad coseno.\n",
    "    \n",
    "    param modelo: Un modelo tipo fastext de gensim\n",
    "    param pregunta_vec: Un ndarray [100,] con la codificación de la frase\n",
    "    param x: Un ndarray [n_ejemplos, 100] con la codificación de los ejemplos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # AGREGA AQUÍ TODO EL CÓDIGO QUE NECESITES\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar tu función, el ejercicio de abajo debería salir:\n",
    "\n",
    "```\n",
    "post_id                4551876\n",
    "title      Java Multithreading\n",
    "tag                       java\n",
    "Name: 295499, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id                4551876\n",
       "title      Java Multithreading\n",
       "tag                       java\n",
       "Name: 295499, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregunta = \"Multithreading in Java\"\n",
    "\n",
    "pregunta_vec = doc_a_vec(normaliza_texto(pregunta).split(), modelo)\n",
    "\n",
    "ind = indices['java']\n",
    "i = recomienda_pregunta(modelo, pregunta_vec, x[ind, :])\n",
    "posicion = indices['java'][i] \n",
    "\n",
    "df_post.loc[posicion,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Poniendo todo junto\n",
    "\n",
    "Por último vamos a poner todo junto como si fuera parte de un sistema de asesoría automática (de hecho es un sistema de recomendación basado en lenguaje natural).\n",
    "\n",
    "Lo primero, vamos a cargar todo lo que necesitamos que ya obtuvimos anteriormente: (si volviste a empezar de cero, la primer celd y las que tienen funciones auxiliares hay que volver a ejecutarlas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('datos/vector_x.npz')['x']\n",
    "\n",
    "modelo = gensim.models.FastText.load_fasttext_format('modelos/fstxt_model')\n",
    "\n",
    "with open(\"modelos/clf_tipo.pkl\", \"rb\") as fp:\n",
    "    clf_tipo = pickle.load(fp)\n",
    "\n",
    "with open(\"modelos/clf_tema.pkl\", \"rb\") as fp:\n",
    "    clf_tema = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora juntemos todo lo que se desarrollo para hacer un recomendador muy sencillito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendador(pregunta, modelo, clf_tipo, clf_tema, df_post):\n",
    "    \"\"\"\n",
    "    Recomienda una respuesta posible a una posible pregunta sobre\n",
    "    programación, basado en un modelo de semantica distrbuida \n",
    "    \n",
    "    :param pregunta: Una cadena de caracteres con una frase\n",
    "    :param modelo: Un modelo tipo fasttext\n",
    "    :param clf_tipo: Clasificado de tipo, > 0, nos interesa el documento\n",
    "    :param clf_tema: Clasificador seleccionador del tema\n",
    "    :param df_post: El dataframe de pandas de las preguntas, tal cual.\n",
    "    \"\"\"\n",
    "    pregunta_vec = doc_a_vec(normaliza_texto(pregunta).split(), modelo)\n",
    "    \n",
    "    if clf_tipo.predict(pregunta_vec.reshape(1, -1)) < 0:\n",
    "        return \"Esta es una pregunta que no nos interesa por el momento, y me da flojera contestarte.\", None\n",
    "    \n",
    "    tag = clf_tema.predict(pregunta_vec.reshape(1, -1))[0]\n",
    "    \n",
    "    pregunta_vec.ravel()\n",
    "    i = recomienda_pregunta(modelo, pregunta_vec, x[indices[tag],:])\n",
    "    ind = indices[tag][i]\n",
    "    \n",
    "    return (\"Hay una pregunta parecida en Stackoverflow sobre el lenguaje {} y dice: \\\n",
    "             \\n <<{}>>\".format(tag, df_post.loc[ind, 'title']),\n",
    "            df_post.loc[ind,'post_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, solo falt porbar nuestro recomendador, a ver que ten bien funciona. Yo puse 10 frases para probarlo. \n",
    "\n",
    "**Agrega otras 10 frases para probarlo. Debe al menos probarse con una pregunta cada uno de los `tags`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay una pregunta parecida en Stackoverflow sobre el lenguaje javascript y dice:              \n",
      " <<How do I include - and ' in this regular expressions?>>\n",
      "\n",
      "Y se puede consultar en https://stackoverflow.com/questions/3659848\n"
     ]
    }
   ],
   "source": [
    "# algunas frases para probar:\n",
    "f1 = \"How to use regular expresions\"\n",
    "f2 = \"How to delete rows in pandas?\"\n",
    "f3 = \"Multithreading in Java\"\n",
    "f4 = \"pandas dataframes\"\n",
    "f5 = \"What is Natural Language Processing?\"\n",
    "f6 = \"What is Artificial Intelligence?\"\n",
    "f7 = \"How to apply word2vec to sentiment analysis\"\n",
    "f8 = \"I want to vrite a program for Iphone 8\"\n",
    "f9 = \"Program with databases in linux\"\n",
    "f10 = \"Program with databases in MacOS\"\n",
    "\n",
    "\n",
    "cadena, idq = recomendador(f1, modelo, clf_tipo, clf_tema, df_post)\n",
    "\n",
    "print(cadena + '\\n')\n",
    "\n",
    "if idq is not None:\n",
    "    pagina = \"https://stackoverflow.com/questions/\" + str(idq)\n",
    "    #display(HTML(url=pagina))\n",
    "    print(\"Y se puede consultar en \" + pagina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prueba tu sistema de recomandación y determina cuando funciona bien, cuando mal y que podríamos hacer para mejorar. Describe todo esto y tus conclusiones aquí mismo abajo de las instrucciones**.\n",
    "\n",
    "ESCRIBE TUS CON CONCLUSIONES AQUI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
